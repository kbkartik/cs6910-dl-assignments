{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkCk6l93GTfE"
      },
      "source": [
        "# GPT-2 Song Generator\n",
        "\n",
        "We first import the libraries needed.\n",
        "\n",
        "Note that we need to set Tensorflow to 1.x as 2.x would lead to problems with [gpt_2_simple](https://github.com/minimaxir/gpt-2-simple)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fsZX2Az4h_i",
        "outputId": "d3dcc2e4-8eaf-492b-8b8d-32eda2a137fb",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "try:\n",
        "  import gpt_2_simple as gpt2\n",
        "except:\n",
        "  !pip3 -q install gpt-2-simple\n",
        "  import gpt_2_simple as gpt2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgmqhDb8E-9K"
      },
      "source": [
        "## Load in text data\n",
        "\n",
        "Files are stored on GitHub, at ThomasVrancken/lyrics_generation.\n",
        "\n",
        "We will load them in a pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "krE-3R4r4lIA",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "dfs = []\n",
        "link = ('https://raw.githubusercontent.com/ThomasVrancken/'\n",
        "        'lyrics_generation/master/songdata_{}.csv')\n",
        "for i in range(4):\n",
        "  dfs.append(pd.read_csv(link.format(i)))\n",
        "\n",
        "df = pd.concat(dfs).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93Ten1_FFIav"
      },
      "source": [
        "Create a copy of the files on colaboratory's VM (most convenient way to read them with GPT-2).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HOyOde-8kCme",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('content'):\n",
        "    os.makedirs('content')\n",
        "  \n",
        "pd.DataFrame({\"lyrics\": df['text']})\\\n",
        "    .to_csv(os.path.join('content', 'lyrics.csv'), index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UNrATp6SPBG"
      },
      "source": [
        "We then download the pretrained models we will be using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XjSlbuijLtE",
        "outputId": "b1d11033-0565-4348-c06a-8fd4df7f1698",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 284Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 4.56Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 836Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:09, 50.9Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 162Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 5.75Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 6.95Mit/s]\n"
          ]
        }
      ],
      "source": [
        "#for model_name in [\"124M\",\"355M\",\"774M\"]:  # Choose from [\"124M\",\"355M\",\"774M\"]\n",
        "gpt2.download_gpt2(model_name='124M')   # model is saved into current directory under /models/124M/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "naQHupkNiPWo",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sh8n7rafi6ew",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.0001\n",
        "optimizer = 'adam' # adam or sgd\n",
        "batch_size = 1\n",
        "model_name = \"124M\" # has to match one downloaded locally\n",
        "tf.compat.v1.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-AkAspY4kHr",
        "outputId": "23f180fd-1cf2-4dc6-e311-9031059efdd5",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n",
            "Loading dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset has 23199731 tokens\n",
            "Training...\n",
            "Saving checkpoint/run1/model-400\n",
            "[800 | 3847.10] loss=1.75 avg=1.75\n",
            "Saving checkpoint/run1/model-800\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1054: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ]
        }
      ],
      "source": [
        "gpt2.finetune(sess,\n",
        "              'content/lyrics.csv',\n",
        "              model_name=model_name,\n",
        "              sample_every=800,\n",
        "              save_every=400,\n",
        "              print_every=800,\n",
        "              learning_rate=learning_rate,\n",
        "              batch_size=batch_size,\n",
        "              restore_from='latest',\n",
        "              steps=800)   # steps is max number of training steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PaBvoGRVJB-2",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "lst_results=gpt2.generate(\n",
        "    sess,\n",
        "    prefix=\"<|startoftext|> I love deep learning!\",\n",
        "    nsamples=5,\n",
        "    temperature=0.95, # change me\n",
        "    top_p=0.95, # Change me\n",
        "    return_as_list=True,\n",
        "    truncate=\"<|endoftext|>\",\n",
        "    include_prefix=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAleBLtrglgl",
        "outputId": "315ef6ec-9316-44b6-8d04-8169b546e207",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|startoftext|> I love deep learning!  \n",
            "  \n",
            "You write music and music that I love to listen to  \n",
            "  \n",
            "It might make you think how the world really does play out  \n",
            "  \n",
            "Those days are hard for me, and it's hard for you to find  \n",
            "  \n",
            "I can't bear the competition  \n",
            "  \n",
            "I can't bear the pressure  \n",
            "  \n",
            "But what you gotta do is see what you got  \n",
            "  \n",
            "I love you deep learning!  \n",
            "You tell me what's true but it's true to me  \n",
            "  \n",
            "You are the reason why I love you deep learning!  \n",
            "You build the foundation of our lives and learn to live with it  \n",
            "  \n",
            "Deep learning is what I just put on the shelf  \n",
            "Deep learning is what I know I'm in for  \n",
            "  \n",
            "I can't bear the competition  \n",
            "  \n",
            "I can't bear the pressure  \n",
            "  \n",
            "But what you gotta do is see what you got  \n",
            "  \n",
            "I love you deep learning!  \n",
            "You tell me what's true but it's true to me  \n",
            "  \n",
            "You are the reason why I love you deep learning!  \n",
            "You build the foundation of our lives and learn to live with it  \n",
            "  \n",
            "Deep learning is what I just put on the shelf  \n",
            "Deep learning is what I know I'm in for\n",
            "\n",
            "\n",
            "\n",
            " -------//------ \n",
            "\n",
            "<|startoftext|> I love deep learning!  \n",
            "Let's be smart as we can!  \n",
            "  \n",
            "Sing off the things we do  \n",
            "I feel so wrong  \n",
            "If I let you do  \n",
            "Then I get the blues  \n",
            "Tell me  \n",
            "  \n",
            "Let's get it together!  \n",
            "Let's feel it together!  \n",
            "  \n",
            "Do it right  \n",
            "Oh, yeah!  \n",
            "I think I'm real kind of mean  \n",
            "I think I'm really, really mean  \n",
            "I think I'm really, really mean  \n",
            "  \n",
            "Say it right  \n",
            "Then dance right, dance right, dance right  \n",
            "  \n",
            "Leave a kiss on my chest  \n",
            "Cause you're looking at me like I'm crazy  \n",
            "I don't know how  \n",
            "  \n",
            "When you left me this high  \n",
            "I left you right here with my heart  \n",
            "And, you know I'm the one, I just can't let it go  \n",
            "  \n",
            "I got you, I got you, I got you, I got you  \n",
            "I got you, I got you, I got you, I got you  \n",
            "I got you, I got you, I got you, I got you  \n",
            "I got you, I got you  \n",
            "I got you, I got you  \n",
            "  \n",
            "Hey, I'm like a king, you like a king, I like a king  \n",
            "I like a king, you like a king, you like a king  \n",
            "I like a king, you like a king, you like a king  \n",
            "I like a king, you like a king  \n",
            "  \n",
            "My name is Kid Rock and I'm a rock and roll man!  \n",
            "Everybody's gonna get smart as a team!  \n",
            "  \n",
            "I just can't give up  \n",
            "You know what I'm thinking  \n",
            "  \n",
            "If I let you do it right, then I get the blues  \n",
            "Tell me  \n",
            "  \n",
            "Let's get it together!  \n",
            "Let's feel it together!  \n",
            "  \n",
            "Do it right  \n",
            "Oh yeah!  \n",
            "I think I'm real kind of mean  \n",
            "I think I'm really, really mean  \n",
            "  \n",
            "Say it right  \n",
            "Then dance right, dance right, dance right  \n",
            "  \n",
            "Leave a kiss on my chest  \n",
            "Cause you're looking at me like I'm crazy  \n",
            "I don't know how  \n",
            "  \n",
            "When you left me this high  \n",
            "I left you right here with my heart  \n",
            "And, you know I'm the one, I just can't let it go  \n",
            "  \n",
            "I got you, I got you, I got you, I got you  \n",
            "I got you, I got you, I got you, I got you  \n",
            "I got you, I got you  \n",
            "I got you, I got you  \n",
            "  \n",
            "(Can't you see that I really, really, really mean it to me  \n",
            "That I really, really mean it to me)  \n",
            "(Can't you see that I really really, really, really mean it to me)  \n",
            "  \n",
            "I got you, I got you, I got you, I got you  \n",
            "I got you, I got you, I got you  \n",
            "I got you, I got you, I got you  \n",
            "I got you, I got you  \n",
            "I got you, I got you  \n",
            "  \n",
            "(Can't you see that I really, really, really mean it to me  \n",
            "That I really, really mean it to me)  \n",
            "(Can't you see that I really really, really mean it to me)  \n",
            "(Can't you see that I really really, really mean it to me)  \n",
            "(Can't you see that I really really, really mean it to me)  \n",
            "  \n",
            "If I let you do it right, then I get the blues  \n",
            "Tell me  \n",
            "  \n",
            "Let's get it together!  \n",
            "Let's feel it together!  \n",
            "  \n",
            "Cause you know I really, really mean it to me  \n",
            "That I really, really mean it to me  \n",
            "That I really, really mean it to me\n",
            "\n",
            "\n",
            "\n",
            " -------//------ \n",
            "\n",
            "<|startoftext|> I love deep learning!  \n",
            "  \n",
            "The fullness of learning!  \n",
            "Deep learning!  \n",
            "  \n",
            "I love deep learning!  \n",
            "  \n",
            "Deep learning!  \n",
            "Deep learning!  \n",
            "Deep learning!  \n",
            "Deep learning!  \n",
            "  \n",
            "Deep learning!  \n",
            "Deep learning!  \n",
            "  \n",
            "So I love deep learning!  \n",
            "Deep learning!  \n",
            "Deep learning!  \n",
            "Deep learning!  \n",
            "Deep learning!\n",
            "\n",
            "\n",
            "\n",
            " -------//------ \n",
            "\n",
            "<|startoftext|> I love deep learning!  \n",
            "This is the most-satisfactory pleasure.  \n",
            "  \n",
            "Deep learning is by-and-large my preferred language.  \n",
            "Deep learning is the thing to do with the mind-set.  \n",
            "  \n",
            "Now I've learned to count from experience.  \n",
            "Deep learning is the inside of a special chair.  \n",
            "Deep learning is like a star climbing the night sky.  \n",
            "  \n",
            "Deep learning is like a pick-measure encrusted with pain.  \n",
            "  \n",
            "Deep learning is the close of my summers home.  \n",
            "Deep learning is the middle of my summer days.  \n",
            "Deep learning is the only light in my back yard.  \n",
            "  \n",
            "Deep learning is like a rich sandy beach through the jungle.  \n",
            "Deep learning is a treasure map outside my hive.  \n",
            "  \n",
            "Deep learning is like a bank terminal with a wire.  \n",
            "Deep learning is the first step I make into a new career.  \n",
            "Deep learning is another step that makes me want to change.  \n",
            "Deep learning is another step that keeps me sane.  \n",
            "Deep learning is why I kept my job.  \n",
            "Deep learning is why I never really let go.  \n",
            "  \n",
            "Deep learning is like a bomb blast from the ground.  \n",
            "Deep learning is my mortal enemy, I've been dying for so long.  \n",
            "Deep learning is a mass of nerve fragments and memories.  \n",
            "Deep learning is my life guarantee.  \n",
            "  \n",
            "Deep learning is like a defense line, this is a defense line.  \n",
            "Deep learning is finally free!  \n",
            "  \n",
            "Deep learning is like a bullet from the nation mines.  \n",
            "Deep learning is a consumer, this is a consumer.  \n",
            "Deep learning is a bubble that's high or low, this is a bubble.  \n",
            "  \n",
            "Deep learning is like a bomb blast from the nation mines.  \n",
            "Deep learning is a consumer, this is a consumer.  \n",
            "Deep learning is a consumer, this is a consumer.\n",
            "\n",
            "\n",
            "\n",
            " -------//------ \n",
            "\n",
            "<|startoftext|> I love deep learning!  \n",
            "Losing in my lesson plan  \n",
            "Get'em over with it and maybe yeah  \n",
            "(Hacksap)  \n",
            " (Cringe)  \n",
            "  \n",
            "[Chorus]  \n",
            "  \n",
            "You like us, your dogs like us  \n",
            "But we only grow together  \n",
            "  \n",
            "Oh honey you like us  \n",
            "I can't stand it if you don't care  \n",
            "I hate how much you care, but we'll fight for a time  \n",
            "  \n",
            "[Chorus x2]  \n",
            "  \n",
            "[Hook]  \n",
            "Get'em over with it and maybe yeah  \n",
            "(Hacksap)  \n",
            "Geez I love you, yeah  \n",
            "(Hacksap)  \n",
            "(Cringe)  \n",
            "(Cringe)  \n",
            "(Hacksap)  \n",
            "  \n",
            "[Chorus x2]  \n",
            "  \n",
            "Your dogs like us, your dogs like us  \n",
            "Oh honey you like us  \n",
            "I can't stand it if you don't care  \n",
            "I hate how much you care, but we'll fight for a time  \n",
            "  \n",
            "[Hook]  \n",
            "[Chorus]  \n",
            "  \n",
            "I love you, my dogs like us  \n",
            "I can't stand it if you don't care  \n",
            "I hate how much you care, but we'll fight for a time  \n",
            "  \n",
            "[Chorus]  \n",
            "  \n",
            "[Hook]  \n",
            "Get'em over with it and maybe yeah  \n",
            "(Hacksap)  \n",
            "Geez I love you, yeah  \n",
            "(Hacksap)  \n",
            "(Cringe)  \n",
            "(Cringe)  \n",
            "(Hacksap)  \n",
            "  \n",
            "[Hook]  \n",
            "Get'em over with it and maybe yeah  \n",
            "(Hacksap)  \n",
            "Geez I love you, yeah  \n",
            "(Hacksap)  \n",
            "(Cringe)  \n",
            "(Hacksap)  \n",
            "(Cringe)  \n",
            "(Hacksap)  \n",
            "  \n",
            "[Hook]  \n",
            "Get'em over with it and maybe yeah  \n",
            "(Hacksap)  \n",
            "(Cringe)  \n",
            "(Hacksap)  \n",
            "(Hacksap)  \n",
            "[Chorus]\n",
            "\n",
            "\n",
            "\n",
            " -------//------ \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for res in lst_results:\n",
        "  print(res)\n",
        "  print('\\n -------//------ \\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7bnKQWKDnzF",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "GPT2 lyric generator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
